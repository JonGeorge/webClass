How to Query using Java to Get All Records from an Index
--------------------------------------------------------


Assumptions:
 A) You have an ElasticSearch instance running (with version 2.3.3)
 B) You are using IntelliJ to create a project
 
 

Procedure
---------
 1. Create a Java command-line project
 
 2. Add these dependencies to your pom.xml

      <dependency>
          <groupId>org.elasticsearch</groupId>
          <artifactId>elasticsearch</artifactId>
          <version>2.3.3</version>
      </dependency>
      
      
      WARNING:  If using ElasticSearch with Apache Storm,
             Then, you might have to exclude the org.jboss.netty to connect to ElasticSearch properly.
             
     		 So, your Apache Storm dependency would look like this:
		      <dependency>
		          <groupId>org.apache.storm</groupId>
		          <artifactId>storm-core</artifactId>
		          <version>0.9.2-incubating</version>
		          <scope>compile</scope>
		          <exclusions>
		               <exclusion>
		                  <!-- Storm comes with jboss.netty and io.netty.  This removed the jboss.netty ones -->
		                  <groupId>org.jboss.netty</groupId>
		                  <artifactId>netty</artifactId>
		              </exclusion>
		          </exclusions>
		      </dependency>
             
              
 
 3. Create this class:  EsClientSingleton
    This singleton class will hold your ElasticSearch Client
		    
		package com.whatever;
		
		import org.elasticsearch.client.Client;
		import org.elasticsearch.client.transport.TransportClient;
		import org.elasticsearch.common.transport.InetSocketTransportAddress;
		import java.net.InetAddress;
		
		/**
		 * Created by adam on 6/25/16.
		 */
		public enum EsClientSingleton
		{
		    INSTANCE;
		
		    private Client esClient;
		
		    /******************************************************************
		     * Private EsClientSingleton Constructor
		     * -- Do one-time initialization here
		     *******************************************************************/
		    private EsClientSingleton()
		    {
		        // The very first time this singleton is called, we will initialize the ES Client
		        initializeEsClientNoException();
		    }
		
		
		    /******************************************************************
		     * initializeEsClient()
		     * -- Attempt to connect to the ElasticSearch Instance
		     *******************************************************************/
		    private void initializeEsClientNoException()
		    {
		        try {
		            // Connect to the ElasticSearch instance using port 9300  [it's a binary protocol]
		            // NOTE:  The java client does not connect to port 9200
		            InetAddress addrEsHostname = InetAddress.getByName("localhost");
		
		            esClient = TransportClient.builder().build()
		                    .addTransportAddress(new InetSocketTransportAddress(addrEsHostname, 9300));
		        }
		        catch (Exception e)
		        {
		            // Convert the exception to a RunTime exception
		            RuntimeException re = new RuntimeException(e);
		            re.setStackTrace(e.getStackTrace());
		            throw re;
		        }
		
		    }
		
		    public Client getEsClient()
		    {
		        return esClient;
		    }
		}
		
				

 4. Create this class:  App
		
		package com.whatever;
		
		import com.fasterxml.jackson.databind.ObjectMapper;
		import org.elasticsearch.action.admin.indices.create.CreateIndexRequest;
		import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;
		import org.elasticsearch.action.index.IndexRequest;
		import org.elasticsearch.action.index.IndexResponse;
		import org.elasticsearch.action.search.SearchResponse;
		import org.elasticsearch.client.Client;
		import org.elasticsearch.common.settings.Settings;
		import org.elasticsearch.common.xcontent.XContentBuilder;
		import org.elasticsearch.indices.IndexAlreadyExistsException;
		import org.elasticsearch.search.SearchHit;
		import org.slf4j.Logger;
		import org.slf4j.LoggerFactory;
		import static org.elasticsearch.common.xcontent.XContentFactory.*;
		
		import java.util.HashMap;
		import java.util.Map;
		
		/**
		 * App
		 *
		 */
		public class App 
		{
		    public static final Logger logger = LoggerFactory.getLogger(App.class);
		
		    public static void main( String[] args ) throws Exception
		    {
		        logger.debug("main() started");
		
		
		        // Connect to the ElasticSearch instance and return the client
		        Client esClient = EsClientSingleton.INSTANCE.getEsClient();
		
		        final String ES_INDEX_NAME = "records-db";
		
		
		        // A T T E M P T      T O     C R E A T E      I N D E X    (within ElasticSearch)
		        try {
		            // Create an index called "music"
		            logger.debug("Attempting co reate the index called '{}'....", ES_INDEX_NAME);
		            Settings indexSettings = Settings.builder()
		                    .put("number_of_shards", 1)
		                    .put("number_of_replicas", 1)
		                    .build();
		            CreateIndexRequest indexRequest = new CreateIndexRequest(ES_INDEX_NAME, indexSettings);
		            CreateIndexResponse res = esClient.admin().indices().create(indexRequest).actionGet();
		        }
		        catch (IndexAlreadyExistsException alreadyExistsException)
		        {
		            // Ignore this exception
		            logger.debug("Ignoring IndexAlreadyExistsException that was raised.");
		        }
		
		        IndexResponse res;
		
		
		        // Add Record Approach #1:  Use a HashMap
		        Map<String, Object> jsonMap = new HashMap<String, Object>();
		        jsonMap.put("createDate", "02/25/2016");
		        jsonMap.put("description", "This is the description for record #1");
		        jsonMap.put("author", "Adam");
		
		        // Create the record and set _type="record" and _id="1"
		        // NOTE:  By setting the ID you can only create this record once.  Calling it multiple times does not add additional records
		        IndexRequest indexRequest = new IndexRequest(ES_INDEX_NAME, "record", "1")
		                                        .source(jsonMap);
		        res = esClient.index(indexRequest).actionGet();
		        logger.debug("After adding record #1. res.isCreated={}  res.getId()={}", res.isCreated(), res.getId());
		
		
		
		        // Add Record Approach #2:  Use a JSON string
		        String sJson = "{  \"createDate\": \"02/26/2016\",        \"description\": \"This is the description for record #2\", \"author\": \"Ben\" }";
		        IndexRequest indexRequest2 = new IndexRequest(ES_INDEX_NAME, "record", "2")
		                                        .source(sJson);
		        res = esClient.index(indexRequest2).actionGet();
		        logger.debug("After adding record #2. res.isCreated={}  res.getId()={}", res.isCreated(), res.getId());
		
		
		
		        // Add Record Approach #3:  Use ElasticSearch helpers to generate JSON
		        XContentBuilder builder = jsonBuilder()
		            .startObject()
		                .field("createDate", "02/28/2016")
		                .field("desciption", "This is the description for record #3")
		                .field("author",     "Justin")
		            .endObject();
		
		        String sJson3 = builder.string();
		        IndexRequest indexRequest3 = new IndexRequest(ES_INDEX_NAME, "record", "3")
		                .source(sJson3);
		        res = esClient.index(indexRequest3).actionGet();
		        logger.debug("After adding record #3. res.isCreated={}  res.getId()={}", res.isCreated(), res.getId());
		
		
		
		        // Add Record Approach #4:  Serialize your object and write the object as a byte[]
		        // NOTE:  Requires adding pom.xml dependency:   com.fasterxml.jackson.core:jackson-databind:2.1.0
		        MyRecord myRecord = new MyRecord("03/01/2016", "This is the description for record #4", "Peter");
		        ObjectMapper mapper = new ObjectMapper(); // create once, reuse
		        byte[] jsonByteArray = mapper.writeValueAsBytes(myRecord);
		        IndexRequest indexRequest4 = new IndexRequest(ES_INDEX_NAME, "record", "4")
		                .source(jsonByteArray);
		        res = esClient.index(indexRequest4).actionGet();
		        logger.debug("After adding record #4. res.isCreated={}  res.getId()={}", res.isCreated(), res.getId());
		
		
		
		        // Search for the records  (you should get 4 hits)
		        SearchResponse searchResponse =
		                esClient.prepareSearch(ES_INDEX_NAME).setTypes("record").execute().actionGet();
		        SearchHit[] hits = searchResponse.getHits().getHits();
		        logger.debug("After running search.  hits.length={}", hits.length);
		
		        
		        logger.debug("main() finished");
		    }
		}
		   
         
 
 5. Startup your local ElasticSearch Instance
 
 6. Run the code
    a. Within Intellij, right-click on the App class -> Run 'App.main()'
    
    b. You should see the following in your console:
    
		06/25/2016 17:23:13 DEBUG com.whatever.App main() started
		06/25/2016 17:23:14 INFO  org.elasticsearch.plugins [Terraxia] modules [], plugins [], sites []
		06/25/2016 17:23:14 DEBUG org.elasticsearch.threadpool [Terraxia] creating thread_pool [generic], type [cached], keep_alive [30s]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.threadpool [Terraxia] creating thread_pool [index], type [fixed], size [6], queue_size [200]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.threadpool [Terraxia] creating thread_pool [fetch_shard_store], type [scaling], min [1], size [12], keep_alive [5m]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.threadpool [Terraxia] creating thread_pool [get], type [fixed], size [6], queue_size [1k]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.threadpool [Terraxia] creating thread_pool [snapshot], type [scaling], min [1], size [3], keep_alive [5m]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.threadpool [Terraxia] creating thread_pool [force_merge], type [fixed], size [1], queue_size [null]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.threadpool [Terraxia] creating thread_pool [suggest], type [fixed], size [6], queue_size [1k]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.threadpool [Terraxia] creating thread_pool [bulk], type [fixed], size [6], queue_size [50]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.threadpool [Terraxia] creating thread_pool [warmer], type [scaling], min [1], size [3], keep_alive [5m]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.threadpool [Terraxia] creating thread_pool [flush], type [scaling], min [1], size [3], keep_alive [5m]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.threadpool [Terraxia] creating thread_pool [search], type [fixed], size [10], queue_size [1k]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.threadpool [Terraxia] creating thread_pool [fetch_shard_started], type [scaling], min [1], size [12], keep_alive [5m]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.threadpool [Terraxia] creating thread_pool [listener], type [fixed], size [3], queue_size [null]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.threadpool [Terraxia] creating thread_pool [percolate], type [fixed], size [6], queue_size [1k]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.threadpool [Terraxia] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.threadpool [Terraxia] creating thread_pool [refresh], type [scaling], min [1], size [3], keep_alive [5m]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.common.network configuration:
		
		lo
		        inet 127.0.0.1 netmask:255.255.255.255 scope:host
		        inet6 ::1 prefixlen:128 scope:host
		        UP LOOPBACK mtu:65536 index:1
		
		eth0
		        inet 192.168.1.159 netmask:255.255.255.0 broadcast:192.168.1.255 scope:site
		        inet6 fe80::a00:27ff:fecb:fa14 prefixlen:64 scope:link
		        hardware 08:00:27:CB:FA:14
		        UP MULTICAST mtu:1500 index:2
		
		06/25/2016 17:23:14 DEBUG org.elasticsearch.common.netty using gathering [true]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.client.transport [Terraxia] node_sampler_interval[5s]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.netty.channel.socket.nio.SelectorUtil Using select timeout of 500
		06/25/2016 17:23:14 DEBUG org.elasticsearch.netty.channel.socket.nio.SelectorUtil Epoll-bug workaround enabled = false
		06/25/2016 17:23:14 DEBUG org.elasticsearch.client.transport [Terraxia] adding address [{#transport#-1}{127.0.0.1}{localhost/127.0.0.1:9300}]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.transport.netty [Terraxia] connected to node [{#transport#-1}{127.0.0.1}{localhost/127.0.0.1:9300}]
		06/25/2016 17:23:14 DEBUG org.elasticsearch.transport.netty [Terraxia] connected to node [{Wiz Kid}{m_vra2t6TiuTtRkZk0BzzQ}{192.168.1.159}{localhost/127.0.0.1:9300}]
		06/25/2016 17:23:14 DEBUG com.whatever.App Attempting co reate the index called 'records-db'....
		06/25/2016 17:23:14 DEBUG com.whatever.App After adding record #1. res.isCreated=true  res.getId()=1
		06/25/2016 17:23:14 DEBUG com.whatever.App After adding record #2. res.isCreated=true  res.getId()=2
		06/25/2016 17:23:14 DEBUG com.whatever.App After adding record #3. res.isCreated=true  res.getId()=3
		06/25/2016 17:23:14 DEBUG com.whatever.App After adding record #4. res.isCreated=true  res.getId()=4
		06/25/2016 17:23:14 DEBUG com.whatever.App After running search.  hits.length=0
		06/25/2016 17:23:14 DEBUG com.whatever.App main() finished
		    
		
		    
		    
		   
