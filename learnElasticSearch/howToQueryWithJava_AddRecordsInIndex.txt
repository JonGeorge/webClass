How to use the Java API to Add Records to an Index
--------------------------------------------------


Assumptions:
 A) You have an ElasticSearch instance running (with version 2.3.3)
 B) Your ElasticSearch instance is listening on localhost and on port 9300
 C) You are using IntelliJ to create a project

 
 

Procedure
---------
 1. Create a Java command-line project
    [see learnJava / howToCreateJavaCommandLineProgramUsingIntellijMaven.txt]
 
 
 2. Add these dependencies to your pom.xml

      <dependency>
          <groupId>ch.qos.logback</groupId>
          <artifactId>logback-classic</artifactId>
          <version>1.0.13</version>
      </dependency>

      <dependency>
          <groupId>com.google.guava</groupId>
          <artifactId>guava</artifactId>
          <version>19.0</version>
      </dependency>

      <dependency>
          <!-- WARNING:  Make sure your ElasticSearch client 2.3.3 matches the version of your ElasticSearch instance -->
          <groupId>org.elasticsearch</groupId>
          <artifactId>elasticsearch</artifactId>
          <version>2.3.3</version>
      </dependency>

      <dependency>
          <!-- Use this to get Jackson's ObjectMapper -->
          <groupId>com.fasterxml.jackson.core</groupId>
          <artifactId>jackson-databind</artifactId>
          <version>2.1.0</version>
      </dependency>
      
      
      WARNING:  
        If running ElasticSearch *AND* using Apache Storm,
        Then, you will need to exclude the org.jboss.netty to connect to ElasticSearch properly.
             
              So, your Apache Storm dependency would look like this:
              <dependency>
                  <groupId>org.apache.storm</groupId>
                  <artifactId>storm-core</artifactId>
                  <version>0.9.2-incubating</version>
                  <scope>compile</scope>
                  <exclusions>
                       <exclusion>
                             <!-- Storm comes with logback-classic.  Let's exclude it -->
                          <exclusion>
                              <groupId>ch.qos.logback</groupId>
                              <artifactId>logback-classic</artifactId>
                          </exclusion>
                          
                          <!-- Storm comes with jboss.netty and io.netty.  This removed the jboss.netty ones -->
                          <groupId>org.jboss.netty</groupId>
                          <artifactId>netty</artifactId>
                      </exclusion>
                  </exclusions>
              </dependency>
             


 3. Update your logback.xml file to look like this:
    a. Edit /src/main/resources/logback.xml
    b. Replace your logback.xml with this:
    
        <?xml version="1.0" encoding="windows-1252" ?>
        <!DOCTYPE project>
        
        <configuration debug="false">
            <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
                <encoder>
                    <pattern>%d{MM/dd/yyyy HH:mm:ss} %-5level %c %m%n</pattern>
                </encoder>
            </appender>
        
        
        
            <logger name="com.wahtever" level="DEBUG" additivity="false">
                <appender-ref ref="CONSOLE"/>
            </logger>
        
            <root level="DEBUG">
                <appender-ref ref="CONSOLE"/>
            </root>
        </configuration>
              
 
 
 4. Create this class:  EsClientSingleton
    a. Right-click on /src/main/java -> New -> Java Class
       Name:  EsClientSingleton
       Kind:  Class
       Press OK
       
    b. Copy this to EsClientSingleton.java 
            
            package com.whatever;
            
            import org.elasticsearch.client.Client;
            import org.elasticsearch.client.transport.TransportClient;
            import org.elasticsearch.common.transport.InetSocketTransportAddress;
            import java.net.InetAddress;
            
            /**
             * Created by adam on 6/25/16.
             */
            public enum EsClientSingleton
            {
                INSTANCE;
            
                private Client esClient;
            
                /******************************************************************
                 * Private EsClientSingleton Constructor
                 * -- Do one-time initialization here
                 *******************************************************************/
                private EsClientSingleton()
                {
                    // The very first time this singleton is called, we will initialize the ES Client
                    initializeEsClientNoException();
                }
            
            
                /******************************************************************
                 * initializeEsClientNoException()
                 * -- Attempt to connect to the ElasticSearch Instance
                 *******************************************************************/
                private void initializeEsClientNoException()
                {
                    try {
                        // Connect to the ElasticSearch instance using port 9300  [it's a binary protocol]
                        // NOTE:  The java client does not connect to port 9200
                        InetAddress addrEsHostname = InetAddress.getByName("localhost");
            
                        esClient = TransportClient.builder().build()
                                .addTransportAddress(new InetSocketTransportAddress(addrEsHostname, 9300));
                    }
                    catch (Exception e)
                    {
                        // Convert the exception to a RunTime exception
                        RuntimeException re = new RuntimeException(e);
                        re.setStackTrace(e.getStackTrace());
                        throw re;
                    }
            
                }
            
                public Client getEsClient()
                {
                    return esClient;
                }
            }
        

                
 5. Create this class:  AddRecords
    a. Right-click on /src/main/java -> New -> Java Class
       Name:  AddRecords
       Kind:  Class
       Press OK
       
    b. Copy this to AddRecords.java 

            package com.whatever;
            
            import com.fasterxml.jackson.databind.ObjectMapper;
            import org.elasticsearch.action.admin.indices.create.CreateIndexRequest;
            import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;
            import org.elasticsearch.action.admin.indices.delete.DeleteIndexRequest;
            import org.elasticsearch.action.admin.indices.delete.DeleteIndexResponse;
            import org.elasticsearch.action.index.IndexRequest;
            import org.elasticsearch.action.index.IndexResponse;
            import org.elasticsearch.action.search.SearchResponse;
            import org.elasticsearch.client.Client;
            import org.elasticsearch.common.settings.Settings;
            import org.elasticsearch.common.xcontent.XContentBuilder;
            import org.elasticsearch.index.IndexNotFoundException;
            import org.elasticsearch.indices.IndexAlreadyExistsException;
            import org.elasticsearch.search.SearchHit;
            import org.slf4j.Logger;
            import org.slf4j.LoggerFactory;
            import static org.elasticsearch.common.xcontent.XContentFactory.*;
            
            import java.util.HashMap;
            import java.util.Map;
            
            /**
             * AddRecords
             *
             */
            public class AddRecords
            {
                public static final Logger logger = LoggerFactory.getLogger(AddRecords.class);
            
                public static void main( String[] args ) throws Exception
                {
                    logger.debug("main() started");
            
            
                    // Connect to the ElasticSearch instance and return the client
                    Client esClient = EsClientSingleton.INSTANCE.getEsClient();
            
                    final String ES_INDEX_NAME = "records-db";
            
            
                    // A T T E M P T      T O     D E L E T E       I N D E X    (within ElasticSearch)
                    try
                    {
                        DeleteIndexResponse deleteResponse = esClient.admin().indices().delete(new DeleteIndexRequest(ES_INDEX_NAME)).actionGet();
                        if (!deleteResponse.isAcknowledged() )
                        {
                            logger.error("I failed to delete this index:  {}", ES_INDEX_NAME);
                        }
                    }
                    catch (IndexNotFoundException notFoundException)
                    {
                        logger.debug("Ignoring IndexNotFoundException that was raised.");
                    }
            
            
                    // A T T E M P T      T O     C R E A T E      I N D E X    (within ElasticSearch)
                    try
                    {
                        // Create an index called "music"
                        logger.debug("Attempting create the index called '{}'....", ES_INDEX_NAME);
                        Settings indexSettings = Settings.builder()
                                .put("number_of_shards", 1)
                                .put("number_of_replicas", 1)
                                .build();
                        CreateIndexRequest indexRequest = new CreateIndexRequest(ES_INDEX_NAME, indexSettings);
                        CreateIndexResponse res = esClient.admin().indices().create(indexRequest).actionGet();
                        if (! res.isAcknowledged())
                        {
                            logger.error("I failed to create this index:  {}", ES_INDEX_NAME);
                        }
                    }
                    catch (IndexAlreadyExistsException alreadyExistsException)
                    {
                        // Ignore this exception
                        logger.debug("Ignoring IndexAlreadyExistsException that was raised.");
                    }
            
                    IndexResponse res;
            
            
                    // Add Record Approach #1:  Use a HashMap
                    Map<String, Object> jsonMap = new HashMap<String, Object>();
                    jsonMap.put("createDate", "02/25/2016");
                    jsonMap.put("description", "This is the description for record #1");
                    jsonMap.put("author", "Adam");
            
                    // Create the record and set _type="record" and _id="1"
                    // NOTE:  By setting the ID you can only create this record once.  Calling it multiple times does not add additional records
                    IndexRequest indexRequest = new IndexRequest(ES_INDEX_NAME, "record", "1")
                                                    .source(jsonMap);
                    res = esClient.index(indexRequest).actionGet();
                    logger.debug("After adding record #1. res.isCreated={}  res.getId()={}", res.isCreated(), res.getId());
            
            
            
                    // Add Record Approach #2:  Use a JSON string
                    String sJson = "{  \"createDate\": \"02/26/2016\",        \"description\": \"This is the description for record #2\", \"author\": \"Ben\" }";
                    IndexRequest indexRequest2 = new IndexRequest(ES_INDEX_NAME, "record", "2")
                                                    .source(sJson);
                    res = esClient.index(indexRequest2).actionGet();
                    logger.debug("After adding record #2. res.isCreated={}  res.getId()={}", res.isCreated(), res.getId());
            
            
            
                    // Add Record Approach #3:  Use ElasticSearch helpers to generate JSON
                    XContentBuilder builder = jsonBuilder()
                        .startObject()
                            .field("createDate", "02/28/2016")
                            .field("desciption", "This is the description for record #3")
                            .field("author",     "Justin")
                        .endObject();
            
                    String sJson3 = builder.string();
                    IndexRequest indexRequest3 = new IndexRequest(ES_INDEX_NAME, "record", "3")
                            .source(sJson3);
                    res = esClient.index(indexRequest3).actionGet();
                    logger.debug("After adding record #3. res.isCreated={}  res.getId()={}", res.isCreated(), res.getId());
            
            
            
                    // Add Record Approach #4:  Serialize your object and write the object as a byte[]
                    // NOTE:  Requires adding pom.xml dependency:   com.fasterxml.jackson.core:jackson-databind:2.1.0
                    MyRecord myRecord = new MyRecord("03/01/2016", "This is the description for record #4", "Peter");
                    ObjectMapper mapper = new ObjectMapper(); // create once, reuse
                    byte[] jsonByteArray = mapper.writeValueAsBytes(myRecord);
                    IndexRequest indexRequest4 = new IndexRequest(ES_INDEX_NAME, "record", "4")
                            .source(jsonByteArray);
                    res = esClient.index(indexRequest4).actionGet();
                    logger.debug("After adding record #4. res.isCreated={}  res.getId()={}", res.isCreated(), res.getId());
            
            
            
                    // Search for the records  (you should get 4 hits)
                    SearchResponse searchResponse =
                            esClient.prepareSearch(ES_INDEX_NAME).setTypes("record").execute().actionGet();
                    SearchHit[] hits = searchResponse.getHits().getHits();
                    logger.debug("After running search.  hits.length={}", hits.length);
            
            
            
                   // esClient.admin().indices();
                   logger.debug("main() finished");
                }
            }
            
             
 6. Startup your local ElasticSearch Instance
    unix> sudo service elasticsearch start
    
    
 7. Run the code
    a. Within Intellij, right-click on the App class -> Run 'AddRecords.main()'
    
    b. You should see the following in your console:
        
        06/25/2016 19:54:54 DEBUG com.whatever.AddRecords main() started
        06/25/2016 19:54:54 INFO  org.elasticsearch.plugins [Steel Serpent] modules [], plugins [], sites []
        06/25/2016 19:54:54 DEBUG org.elasticsearch.threadpool [Steel Serpent] creating thread_pool [generic], type [cached], keep_alive [30s]
        06/25/2016 19:54:54 DEBUG org.elasticsearch.threadpool [Steel Serpent] creating thread_pool [index], type [fixed], size [6], queue_size [200]
        06/25/2016 19:54:54 DEBUG org.elasticsearch.threadpool [Steel Serpent] creating thread_pool [fetch_shard_store], type [scaling], min [1], size [12], keep_alive [5m]
        06/25/2016 19:54:54 DEBUG org.elasticsearch.threadpool [Steel Serpent] creating thread_pool [get], type [fixed], size [6], queue_size [1k]
        06/25/2016 19:54:54 DEBUG org.elasticsearch.threadpool [Steel Serpent] creating thread_pool [snapshot], type [scaling], min [1], size [3], keep_alive [5m]
        06/25/2016 19:54:54 DEBUG org.elasticsearch.threadpool [Steel Serpent] creating thread_pool [force_merge], type [fixed], size [1], queue_size [null]
        06/25/2016 19:54:54 DEBUG org.elasticsearch.threadpool [Steel Serpent] creating thread_pool [suggest], type [fixed], size [6], queue_size [1k]
        06/25/2016 19:54:54 DEBUG org.elasticsearch.threadpool [Steel Serpent] creating thread_pool [bulk], type [fixed], size [6], queue_size [50]
        06/25/2016 19:54:54 DEBUG org.elasticsearch.threadpool [Steel Serpent] creating thread_pool [warmer], type [scaling], min [1], size [3], keep_alive [5m]
        06/25/2016 19:54:54 DEBUG org.elasticsearch.threadpool [Steel Serpent] creating thread_pool [flush], type [scaling], min [1], size [3], keep_alive [5m]
        06/25/2016 19:54:54 DEBUG org.elasticsearch.threadpool [Steel Serpent] creating thread_pool [search], type [fixed], size [10], queue_size [1k]
        06/25/2016 19:54:54 DEBUG org.elasticsearch.threadpool [Steel Serpent] creating thread_pool [fetch_shard_started], type [scaling], min [1], size [12], keep_alive [5m]
        06/25/2016 19:54:54 DEBUG org.elasticsearch.threadpool [Steel Serpent] creating thread_pool [listener], type [fixed], size [3], queue_size [null]
        06/25/2016 19:54:54 DEBUG org.elasticsearch.threadpool [Steel Serpent] creating thread_pool [percolate], type [fixed], size [6], queue_size [1k]
        06/25/2016 19:54:54 DEBUG org.elasticsearch.threadpool [Steel Serpent] creating thread_pool [management], type [scaling], min [1], size [5], keep_alive [5m]
        06/25/2016 19:54:54 DEBUG org.elasticsearch.threadpool [Steel Serpent] creating thread_pool [refresh], type [scaling], min [1], size [3], keep_alive [5m]
        06/25/2016 19:54:54 DEBUG org.elasticsearch.common.network configuration:
        
        lo
                inet 127.0.0.1 netmask:255.255.255.255 scope:host
                inet6 ::1 prefixlen:128 scope:host
                UP LOOPBACK mtu:65536 index:1
        
        eth0
                inet 192.168.1.159 netmask:255.255.255.0 broadcast:192.168.1.255 scope:site
                inet6 fe80::a00:27ff:fecb:fa14 prefixlen:64 scope:link
                hardware 08:00:27:CB:FA:14
                UP MULTICAST mtu:1500 index:2
        
        06/25/2016 19:54:54 DEBUG org.elasticsearch.common.netty using gathering [true]
        06/25/2016 19:54:55 DEBUG org.elasticsearch.client.transport [Steel Serpent] node_sampler_interval[5s]
        06/25/2016 19:54:55 DEBUG org.elasticsearch.netty.channel.socket.nio.SelectorUtil Using select timeout of 500
        06/25/2016 19:54:55 DEBUG org.elasticsearch.netty.channel.socket.nio.SelectorUtil Epoll-bug workaround enabled = false
        06/25/2016 19:54:55 DEBUG org.elasticsearch.client.transport [Steel Serpent] adding address [{#transport#-1}{127.0.0.1}{localhost/127.0.0.1:9300}]
        06/25/2016 19:54:55 DEBUG org.elasticsearch.transport.netty [Steel Serpent] connected to node [{#transport#-1}{127.0.0.1}{localhost/127.0.0.1:9300}]
        06/25/2016 19:54:55 DEBUG org.elasticsearch.transport.netty [Steel Serpent] connected to node [{Annex}{kKIXGfeeTAKAfQUCjW_Xpw}{192.168.1.159}{localhost/127.0.0.1:9300}]
        06/25/2016 19:54:55 DEBUG com.whatever.AddRecords Attempting create the index called 'records-db'....
        06/25/2016 19:54:55 DEBUG com.whatever.AddRecords After adding record #1. res.isCreated=true  res.getId()=1
        06/25/2016 19:54:55 DEBUG com.whatever.AddRecords After adding record #2. res.isCreated=true  res.getId()=2
        06/25/2016 19:54:55 DEBUG com.whatever.AddRecords After adding record #3. res.isCreated=true  res.getId()=3
        06/25/2016 19:54:55 DEBUG com.whatever.AddRecords After adding record #4. res.isCreated=true  res.getId()=4
        06/25/2016 19:54:55 DEBUG com.whatever.AddRecords After running search.  hits.length=0
        06/25/2016 19:54:55 DEBUG com.whatever.AddRecords main() finished
        

           
