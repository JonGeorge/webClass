Introduction to Apache Storm
----------------------------


References
----------
http://storm.apache.org/releases/current/Tutorial.html
http://blog.zymr.com/introduction-to-apache-storm



A Storm cluster is superficially similar to a Hadoop Cluster:
  -- On a Hadoop Cluster you run MapReduce jobs.  And, the MapReduce jobs eventually finish.
  -- On a Storm cluster, you run Toplogies.  Topologies process message forever (or until you kill it)
  
  
A Storm cluster has 2 kinds of nodes:
 1) Master Node:  Runs a daemon called "Nimbus" that is similar to Hadoop's JobTracker.  
                  It distributes code around the cluster
                  It assigns tasks to machines
                  It monitors for failures
                  
 2) Worker Nodes: Runs a daemon called "Supervisor".
                  Listens for work assigned to its machine
                  Starts & Stops work perocesses as necessary
                  Each worker process executes a subset of a toplogy
                  A running topology consists of many worker processes spread cross many machines

All coordinates between Nimbus and the Supervisors is done through a Zookeeper cluster.  
-- The Nimbus and Supervisor daemons are fail-fast and stateless
-- All steps are kept in Zookeeeper or on local disk
-- You can run kill the Nimbus or Supervisors and they'll start back up as if nothing happened
-- This design leads to Storm clusters being incredibly stable

Zookeeper as you can see sits there in the middle. Since Storm is stateless, it uses Zookeeper to share and sync data between them
Nimbus hands-off work to the Supervisors [which exists to process Bolts and Spouts]

Components
----------
 1) Spouts are input data.  
 2) Bolt are output data.
 3) Tuples (ordered sets) can contain any type of data
 4) Topology is a directed graph where vertices are computation and edges are a stream of data"
  Spout1 --> Bolt1  --> Boltd
         --> Bolt2  --> Bolt3
  Spout2 --> Bolt1

Streams
-------
A stream is an unbounded sequence of tuples between two nodes in the topology.
Nodes can accept 1 or more streams as input
Nodes perform some computation or transformation on the input tuples and emit new tuples, thus creating a new output stream
These output streams act as input streams for other nodes


Spouts
------
A spout is the source of a stream in the topology
Spouts normally read data from an external data source and emit tuples into the topology
Spouts listen on lots of different things 
  a) message queues for incoming messages
  b) database for changes
  c) some other feed of data
Spouts don't perform any processing


Bolts
-----
Bolt accepts a tuple from its input stream, performs a computation or transformation and then (optionally) emits a new tuple(s) to its output stream(s)



How to Write a Storm Analytic
-----------------------------
Write a spout
Write a bolt
Make it run by writing a topology  -- e.g., a Java class with a Main method inside of it.  To make it run forever, you would put it inside a loop


Download Apache Storm here:
   http://storm.apache.org/downloads.html
