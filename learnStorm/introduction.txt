Introduction to Apache Storm
----------------------------
A Storm cluster is superficially similar to a Hadoop Cluster:
  -- On a Hadoop Cluster you run MapReduce jobs.  And, the MapReduce jobs eventually finish.
  -- On a Storm cluster, you run Toplogies.  Topologies process message forever (or until you kill it)
  
  
A Storm cluster has 2 kinds of nodes:
 1) Master Node:  Runs a daemon called "Nimbus" that is similar to Hadoop's JobTracker.  
                  It distributes code around the cluster
                  It assigns tasks to machines
                  It monitors for failures
                  
 2) Worker Nodes: Runs a daemon called "Supervisor".
                  Listens for work assigned to its machine
                  Starts & Stops work perocesses as necessary
                  Each worker process executes a subset of a toplogy
                  A running topology consists of many worker processes spread cross many machines

All coordinates between Nimbus and the Supervisors is done through a Zookeeper cluster.  
-- The Nimbus and Supervisor daemons are fail-fast and stateless
-- All steps i kept in Zookeeeper or on local disk
-- You can run kill the Nimbus or Supervisors and they'll start back up as if nothing happened
-- This design leads to Storm clusters being incredibly stable


References
----------
http://storm.apache.org/releases/current/Tutorial.html


Download Apache Storm here:
   http://storm.apache.org/downloads.html
