How to Debug a Map-Reduce Job to Parse XML using Intellij
---------------------------------------------------------

Assumptions:
 A) You have Intellij Commnity Edition 14 installed
 B) You have a Java JDK
 C) You have HDFS setup and installed [see howToCompile AndInstallHdfsOnWindows.txt]
 D) You have hadoop running in "Local" mode
 
 
References
----------
http://blog.mafr.de/2010/07/24/maven-hadoop-job/     (how to build runnable hadoop job)



Procedures
----------
 1. Create your mrParseXml Map-Reduce Project
    a. Startup Intellij
       NOTE:  If an existing Intellij project appear, then pull File / Close Project
       
    b. Press "Create New Project"
       1) In the "New Project" window, 
            a) Select Maven [on the left]
            b) Next to Project SDK:  Select your Java JDK
               NOTE:  If you do not see your java JDK, then
                      Press New
                      -- Browse to your Java JDK:  C:\Program Files\Java\jdk1.7.0_60
                      -- Press OK
               
            c) Check "Create from archetype"
            d) Select maven-archetype-quickstart
               Press Next
               
       2) In the next screen
          GroupId:     com.whatever
          ArtifactId:  mrParseXml    
          Version:     1.0-SNAPSHOT
          Press Next
          
          
       3) In the next screen,
          Maven home directory:  C:/tools/apache-maven-3.2.3
          User settings file:    Check the checkbox to "Override"
                                 C:\tools\apache-maven-3.2.3\conf\settings.xml
          Press Next                       
                                 
       
       4) Project Name:      mrParseXml
          Project Location:  C:\tools\intellij\workspace\mrParseXml
          Press Finish
          
       5) If you get prompted that "C:\tools\intellij\workspace\mrParseXml" does not exist
          It will be created by Intellij
          Press OK 
     
       6) If you get prompted 
          "New projects can either be opened in a new window or replace the project"
          Press "This Window"
          
       7) If you are prompted 
          Maven projects need to be imported
          Press "Enable Auto-Import"
          
          Now, maven has created a simple Java JAR project
         
 
 
 2. Configure Intellij preferences for this project
    a. Turn off spell-checking
       1) Pull File / Settings
       2) Search for spelling
          a) Single-click on Inspections
          b) next to Typo -- Uncheck the checkbox
          c) Press Apply, Press OK
          


 3. In Intellij, exclude build directory
    a. Pull File / Settings
    b. Search for maven
       Select Build Tools -> Maven -> Importing
       Uncheck exclude build directory
       Press Apply, Press OK
     


 4. Setup the Maven directories for your Intellij project

    Add these directories
       src/test/resources/             # Holds the logback.xml used by unit test code
       src/main/assembly/              # Holds the hadoop-job.xml file
       src/main/config/                # Simulates the HADOOP_CLASSPATH to hold log4j.xml and property file
           
    a. Right-click on src/test   -> New -> Directory:    resources
    b. Right-click on src/main   -> New -> Directory:    config
    c. Right-click on src/main   -> New -> Directory:    assembly
    

    Now, you should have this directory structure
      src/main/assembly/
      src/main/config/                   
      src/main/java/
      src/test/java
      src/test/resources/    


           
 5. Add dependencies for logging and map-reduce
    Your pom.xml should already have one dependency:
      <dependencies>
      
        <dependency>
          <groupId>junit</groupId>
          <artifactId>junit</artifactId>
          <version>3.8.1</version>
          <scope>test</scope>
        </dependency>
        
      </dependencies>
    
        
        
    Copy and paste these dependencies into your pom.xml
    NOTE:  Add all of these dependencies should be between these tags:
       <dependencies>
       . . .
       </dependencies>
       
     
    
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-core</artifactId>
            <version>1.2.1</version>
            <scope>provided</scope>
        </dependency>
    
        <dependency>
            <groupId>org.apache.commons</groupId>
            <artifactId>commons-lang3</artifactId>
            <version>3.3.2</version>
        </dependency>
    
    
        <dependency>
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-api</artifactId>
            <version>1.7.5</version>
        </dependency>
    
        <dependency>
            <!-- Hadoop uses log4j so use SLF4j w/log4j bridge -->
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-log4j12</artifactId>
            <version>1.7.12</version>
        </dependency>
    
        <dependency>
            <!-- Jaxb library to parse XML -->
            <groupId>javax.xml.bind</groupId>
            <artifactId>jaxb-api</artifactId>
            <version>2.2.12</version>
          </dependency>
    
        <dependency>
            <!-- I need this dependency to get XmlInputFormat.class -->
            <groupId>org.apache.mahout</groupId>
            <artifactId>mahout-integration</artifactId>
            <version>0.10.1</version>
        </dependency>




 6. Setup Maven to create a runnable Hadoop JAR that has all of the dependent JARs inside of it
    a. Browse to src/main/assembly
    b. Add a file:  hadoop-job.xml
    c. Copy this to your hadoop-job.xml
             
        <assembly>
            <id>job</id>
            <formats>
                <format>jar</format>
            </formats>
            <includeBaseDirectory>false</includeBaseDirectory>
            <dependencySets>
                <dependencySet>
                    <unpack>false</unpack>
                    <scope>runtime</scope>
                    <outputDirectory>lib</outputDirectory>
                    <excludes>
                        <exclude>${groupId}:${artifactId}</exclude>
                    </excludes>
                </dependencySet>
                <dependencySet>
                    <unpack>true</unpack>
                    <includes>
                        <include>${groupId}:${artifactId}</include>
                    </includes>
                </dependencySet>
            </dependencySets>
        </assembly>
    
    d. Browse to your pom.xml
    e. Add this to the end of your <plugins>...</plugins> section
            <plugin>
                <!-- Build the runnable hadoop job JAR file -->
                <!-- NOTE:  Any dependencies with scope=provided will not be added to this JAR -->
                <artifactId>maven-assembly-plugin</artifactId>
                <version>2.2.1</version>
                <configuration>
                    <descriptors>
                        <descriptor>src/main/assembly/hadoop-job.xml</descriptor>
                    </descriptors>
                </configuration>
                <executions>
                    <execution>
                        <id>make-assembly</id>
                        <phase>package</phase>
                        <goals>
                            <goal>single</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
            
            
            

 7. Create this file:  log4j.xml    [in src/main/config/ directory]
    NOTES:
      -- Hadoop uses log4j so we must, too...
      -- Normally, we would put this file in src/main/resources
         But, because this is a hadoop job we put in src/main/config
      -- When running the hadoop job, we will set HADOOP_CLASSPATH to be the src/main/config directory
         so that Hadoop can find the files in this directory
      -- Remember:  Hadoop runs this JAR file [and not you]  
          
    a. Browse to src/main/config
    b. Right-click on classes -> New -> Other... -> Search for file
       filename:  log4j.xml
       
        <?xml version="1.0" encoding="UTF-8" ?>
        <!DOCTYPE log4j:configuration SYSTEM "log4j.dtd">
        
        <log4j:configuration xmlns:log4j="http://jakarta.apache.org/log4j/">
            <appender name="CONSOLE" class="org.apache.log4j.ConsoleAppender">
                <param name="Target" value="System.out"/>
                <layout class="org.apache.log4j.PatternLayout">
                    <param name="ConversionPattern" value="%d{MM/dd/yyyy HH:mm:ss} %t %c %m%n"/>
                </layout>
            </appender>
        
        
            <logger name="com.whatever" additivity="false">
                <level value="debug" />
                <appender-ref ref="CONSOLE" />
            </logger>
        
            <root>
                <priority value="info" />
                <appender-ref ref="CONSOLE" />
            </root>
        
        </log4j:configuration>
  
  
  
 8. Create this file:  ParseXml.properties  [in src/main/config/ directory]
    a. Browse to src/main/config
    b. Add this file:  ParseXml.properties
    
        #
        # ParseXml.properties
        #
        inputPath=c:/temp/mrParseXml/input
        outputPath=c:/temp/mrParseXml/output
        lookupCacheFilePath=c:/temp/mrParseXml/cache/lookupFile.txt 
   
   
   
 9. In Intellij, create your Employee class
    a. Browse to src/main/java/com.whatever -> New Java Class
    b. Name:  Employee
       Press OK
    c. Copy this to your class 
    
        package com.whatever;
        
        import javax.xml.bind.annotation.*;
        
        /**
         * Created by adam on 8/1/2015.
         */
        @XmlRootElement(name="Employee")
        @XmlAccessorType(XmlAccessType.FIELD)
        public class Employee
        {
            @XmlAttribute
            private int id;
        
            // Employee's first name
            @XmlElement
            private String firstName;
        
            // Employee's middle name
            @XmlElement
            private String middleName;
        
            // Employee's last name
            @XmlElement
            private String lastName;
        
            // Employee no argument constructor
            public Employee()
            {
            }
        
            public int getId()
            {
                return id;
            }
        
            public void setId(int id)
            {
                this.id = id;
            }
        
            public String getLastName()
            {
                return lastName;
            }
        
            public void setLastName(String lastName)
            {
                this.lastName = lastName;
            }
        
            public String getMiddleName()
            {
                return middleName;
            }
        
            public void setMiddleName(String middleName)
            {
                this.middleName = middleName;
            }
        
            public String getFirstName()
            {
                return firstName;
            }
        
            public void setFirstName(String firstName)
            {
                this.firstName = firstName;
            }
        
            @Override
            public boolean equals(Object o)
            {
                if (this == o) return true;
                if (o == null || getClass() != o.getClass()) return false;
        
                Employee employee = (Employee) o;
        
                if (id != employee.id) return false;
                if (firstName != null ? !firstName.equals(employee.firstName) :
                        employee.firstName != null) return false;
                if (lastName != null ? !lastName.equals(employee.lastName) :
                        employee.lastName != null) return false;
                if (middleName != null ? !middleName.equals(employee.middleName) :
                        employee.middleName != null) return false;
        
                return true;
            }
        
            @Override
            public int hashCode()
            {
                int result = id;
                result = 31 * result + (firstName != null ? firstName.hashCode() : 0);
                result = 31 * result + (middleName != null ? middleName.hashCode() : 0);
                result = 31 * result + (lastName != null ? lastName.hashCode() : 0);
                return result;
            }
        
            @Override
            public String toString()
            {
                return "Employee{" +
                        "id=" + id +
                        ", firstName='" + firstName + '\'' +
                        ", middleName='" + middleName + '\'' +
                        ", lastName='" + lastName + '\'' +
                        '}';
            }
        }


   
10. in Intellij, create your ParseXml class 
    a. Browse to src/main/java/com.whatever -> New Java Class
    b. Name:  ParseXml
       Press OK
    c. Copy this to your class
    
            package com.whatever;
            
            import java.io.*;
            import java.net.URI;
            import java.util.Properties;
            import java.util.TreeMap;
            
            import org.apache.commons.lang3.StringUtils;
            import org.apache.hadoop.conf.Configuration;
            import org.apache.hadoop.conf.Configured;
            import org.apache.hadoop.filecache.DistributedCache;
            import org.apache.hadoop.fs.FileSystem;
            import org.apache.hadoop.fs.Path;
            import org.apache.hadoop.io.LongWritable;
            import org.apache.hadoop.io.Text;
            import org.apache.hadoop.mapreduce.Job;
            import org.apache.hadoop.mapreduce.Mapper;
            import org.apache.hadoop.mapreduce.Reducer;
            import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
            import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
            import org.apache.hadoop.util.Tool;
            import org.apache.hadoop.util.ToolRunner;
            import org.apache.mahout.text.wikipedia.XmlInputFormat;
            import org.slf4j.Logger;
            import org.slf4j.LoggerFactory;
            
            import javax.xml.bind.JAXBContext;
            import javax.xml.bind.Unmarshaller;
            
            public class ParseXml extends Configured implements Tool
            {
                private static final Logger logger = LoggerFactory.getLogger(ParseXml.class);
            
                private static final String INPUT_PATH_PROP_KEY = "inputPath";
                private static final String OUTPUT_PATH_PROP_KEY = "outputPath";
                private static final String LOOKUP_CACHE_FILEPATH_PROP_KEY = "lookupCacheFilePath";
            
                /**************************************************************
                 * main()
                 *   1) Create a logback.xml file and put in directory
                 *   2) Create a property file called  ParseXml.properties
                 *       inputPath=hdfs:/data/2015
                 *       outputPath=hdfs:/reports/rp1
                 *       lookupCacheFilePath=hdfs:/cache/cacheFile.txt
                 *   3) unix> export HADOOP_CLASSPATH=/directory/that/holds/property/file
                 *   4) unix> hadoop jar myFile.jar com.whatever.ParseXml
                 *
                 * Mapper
                 *   1) Parse the XML using JAXB
                 *   2) Pull-out part of XML and write to reducer
                 *
                 * Reduer
                 *   1) Load distributed cache file into TreeMap
                 *   2) Join value from mapper to distributed cache file
                 *   3) Write joined value to output
                 ***************************************************************/
                public static void main(String[] args) throws Exception
                {
                    ToolRunner.run(new Configuration(), new ParseXml(), args);
                }
            
            
                @Override
                public int run(String[] strings) throws Exception
                {
            
                    logger.debug("main() started");
            
                    // Read-in property file called "ParseXml.properties"
                    InputStream iostream = ParseXml.class.getResourceAsStream("/ParseXml.properties");
                    if (iostream == null)
                    {
                        throw new RuntimeException("Critical Error in ParseXml.run():  I could not find ParseXml.properties in your HADOOP_CLASSPATH");
                    }
            
                    // Put the contents of the property file into the props object
                    Properties props = new Properties();
                    props.load(iostream);
            
                    // Close the iostream
                    iostream.close();
            
                    // Verify that the required property keys are found and that values are actually present
                    //   verifyPropertyValues(props);
            
                    // Create a new job with an empty configuration
                    Job job = new Job(new Configuration());
            
                    // Get a pointer to the job's configuration
                    Configuration conf = job.getConfiguration();
            
                    job.setJobName("ParseXml Job");
                    job.setJarByClass(ParseXml.class);
                    job.setMapperClass(MyMapper.class);
                    job.setReducerClass(MyReducer.class);
                    job.setOutputKeyClass(Text.class);
                    job.setOutputValueClass(Text.class);
                    job.setInputFormatClass(XmlInputFormat.class);
            
                    conf.set(XmlInputFormat.START_TAG_KEY, "<Employee");
                    conf.set(XmlInputFormat.END_TAG_KEY, "</Employee>");
            
                    // Setup the input directory
                    String sInputPath = props.getProperty(INPUT_PATH_PROP_KEY);
                    FileInputFormat.addInputPath(job, new Path(sInputPath));
            
                    // Setup the output directory
                    String sOutputPath = props.getProperty(OUTPUT_PATH_PROP_KEY);
                    FileOutputFormat.setOutputPath(job,  new Path(sOutputPath));
            
                    // Setup the distributed cache
                    String sLookupCacheFilePath = props.getProperty(LOOKUP_CACHE_FILEPATH_PROP_KEY);
                    Path pLookupCatchFilePath = new Path(sLookupCacheFilePath);
                    DistributedCache.addCacheFile(pLookupCatchFilePath.toUri(), conf);
            
                    // Run the job
                    boolean bJobFinishedSuccessfully = job.waitForCompletion(true);
            
                    if (bJobFinishedSuccessfully)
                    {
                        logger.debug("Job finished successfully");
                        return 0;
                    }
                    else
                    {
                        logger.debug("Job Failed");
                        return 1;
                    }
            
                }
            
            
            
                //  M A P P E R       C L A S S
                public static class MyMapper extends Mapper<LongWritable, Text, Text, Text>
                {
            
                    public void setup(Mapper.Context context) throws IOException, InterruptedException
                    {
                        logger.debug("MyMapper.setup() called");
                    }
            
                    public void map(LongWritable aKey, Text aValue, Context aContext) throws IOException, InterruptedException
                    {
                        try {
                            String sEmployeeXml = aValue.toString();
            
                            // Convert the XML into an Employee object
                            final JAXBContext jaxbContext = JAXBContext.newInstance(Employee.class);
                            Unmarshaller unmarshaller = jaxbContext.createUnmarshaller();
                            StringReader reader = new StringReader(sEmployeeXml);
                            final Employee employee = (Employee) unmarshaller.unmarshal(reader);
            
            
                            aContext.write(new Text(String.valueOf(employee.getId())),
                                           new Text(employee.getLastName() + ";" + employee.getFirstName() ) );
                        }
                        catch (Exception e)
                        {
                            RuntimeException re = new RuntimeException("Exception raised in MyMapper.map", e);
                            re.setStackTrace(e.getStackTrace() );
                            throw re;
                        }
                    }
                }
            
            
            
                //  R E D U C E R       C L A S S
                public static class MyReducer extends Reducer<Text,Text,Text,Text>
                {
                    private TreeMap<String, String> lookupCache = new TreeMap<String, String>();
            
            
                    /*************************************************************************
                     * setup()
                     *
                     * Initialize the lookup cache by reading the distributed cache file
                     *************************************************************************/
                    public void setup(Reducer.Context aContext) throws IOException, InterruptedException
                    {
                        Configuration jobConf = aContext.getConfiguration();
            
                        URI[] cacheFileUris = DistributedCache.getCacheFiles(jobConf);
            
                        // verify that cacheFileUris is only one element
                        if (cacheFileUris == null)
                        {
                            throw new RuntimeException("Critical Error in MyReducer.setup()  cacheFileUris is null.  This means that the distributed cache was not setup correctly.");
                        }
                        else if (cacheFileUris.length == 0)
                        {
                            throw new RuntimeException("Critical Error in MyReducer.setup()  cacheFileUris is empty.  This means that the distributed cache was not setup correctly.");
                        }
                        else if (cacheFileUris.length > 1)
                        {
                            throw new RuntimeException("Critical Error in MyReducer.setup()  cacheFileUris.length is " + cacheFileUris.length + ".  It should be one.  This means that the distributed cache was not setup correctly.");
                        }
            
                        Path pathCacheFile = new Path(cacheFileUris[0].getPath());
            
                        // Open this file
                        FileSystem fs = FileSystem.get(jobConf);
                        BufferedReader fileReader = new BufferedReader(new InputStreamReader(fs.open(pathCacheFile)));
                        String sLine;
            
                        while ((sLine = fileReader.readLine()) != null)
                        {
                            // add stuff into some lookup treemap or hashmap
                            String[] parts = StringUtils.split(sLine, ",");
            
                            lookupCache.put(parts[0], parts[1]);
                        }
            
                        fileReader.close();
                        fs.close();
            
                        logger.debug("The lookup cache has a total of {} elements in it.", lookupCache.size() );
                    }
            
            
            
                    /*************************************************************************
                     * reduce()
                     *************************************************************************/
                    public void reduce(Text aKey, Iterable<Text> aValues, Context aContext) throws IOException, InterruptedException
                    {
                        for (Text tValue: aValues)
                        {
                            aContext.write(aKey, tValue);
                        }
                    }
                }
            }
             
             
             
11. Setup your input directory and an input file
    a. Create this directory: c:\temp\mrParseXml\input
    b. Create a file called   c:\temp\mrParseXml\input\file1.xml
       NOTE:  The name does not matter
       
        <?xml version="1.0" encoding="UTF-8" standalone="yes"?>
        <Employee id="1">
          <firstName>Adam</firstName>
          <middleName>L</middleName>
          <lastName>Resnick</lastName>
        </Employee>
        
        <Employee id="2">
          <firstName>Ben</firstName>
          <middleName>M</middleName>
          <lastName>Resnick</lastName>
        </Employee>
        
        <Employee id="3">
          <firstName>Peter</firstName>
          <middleName>F</middleName>
          <lastName>Resnick</lastName>
        </Employee>
        
        <Employee id="4">
          <firstName>Justin</firstName>
          <middleName>D</middleName>
          <lastName>Resnick</lastName>
        </Employee>

         
11b. **OPTIONAL** 
    Only use this step if running Hadoop in pseudo-distributed mode
    
    Setup the HDFS directories and test data
    a. Create the HDFS directorires /tmp/input 
       DOS> hadoop fs -mkdir /tmp/input
       DOS> hadoop fs -rmdir /tmp/output
       
    b. Create a file called c:\temp\stuff.txt with this
            hi mom
            hi Ben
            hi Peter
            hi Dad
            hi Will
            hi Sam
            Will is cool
    
    c. Put that file in the /tmp/input direcory in HDFS
       DOS> hadoop fs -put c:\temp\stuff.txt /tmp/input/stuff.txt
  
  
      
12. Setup your lookup file cache
    a. Create this directory: c:\temp\mrParseXml\cache
    b. Create a file called   c:\temp\mrParseXml\cache\lookupFile.txt
    
       Copy this to your file
            id,annual salary
            1,150000
            2,20000
            3,40000
            4,60000   
  
      
      
13. In Intellij, setup Remote debugging
    a. Pull Run / Edit Configurations
    b. Click the "+" on the left
    c. Click on "Remote"
       Name:           hadoop-job
       Transport:      Socket
       Debugger mode:  Attach
       Host:           localhost
       Port:           5005
       Press Apply
       Press OK
       
   
   
14. Build your runnable Hadoop JAR file
    a. Open a DOS window by pressing <Start><Run>CMD
    b. In the DOS window, type-in this:
       DOS> cd /d c:\tools\intellij\workspace\mrParseXml
       DOS> mvn clean package
       
       Now, you have this JAR
          c:\tools\intellij\workspace\mrParseXml\target\mrParseXml-1.0-SNAPSHOT-job.jar
          c:\tools\intellij\workspace\mrParseXml\target\mrParseXml-1.0-SNAPSHOT.jar
     
       The file that ends with "-job" has all of the dependent JARs inside of it
       
       
       
15. Run your hadoop java jar in debug mode
    a. Make sure your test data is setup
       If running in "Local" mode, then make sure you have a file in c:\temp\input
       If running in "Psuedo-distributed" mode, then 
         -- Make sure your HDFS system is turned on
         -- Make sure your have a /tmp/input/stuff.txt file in your HDFSMake sure your HDFS system is turned on
             
    b. Open a DOS window in Administrative mode
       Run these commands
       
       1) Setup Hadoop to run in debug mode   
          DOS> set HADOOP_OPTS=-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5005
           
       2) Setup HADOOP_CLASSPATH to the directory that holds log4j.xml *AND* ParseXml.properties
          DOS> set HADOOP_CLASSPATH=C:\tools\intellij\workspace\mrParseXml\src\main\config
    
       3) If running Hadoop in "Local" mode
          Run your hadoop job in debugging mode 
          DOS> cd /d c:\tools\intellij\workspace\mrParseXml
          DOS> hadoop jar .\target\mrParseXml-1.0-SNAPSHOT-job.jar com.whatever.ParseXml
              
          You should see Listening for transport dt_socket at address 5005
      
      
      
16. In Intellij, connect to the hadoop job remotely
    a. Set a breakpoint
    b. Pull Run / Debug hadoop-job
    


17. Look at the results
   
    If running Hadoop in "Local" mode, then your results are in C:\temp\mrParseXml\output
    


In order to run again (in local mode)
 -- Delete the output directory (C:\temp\mrParseXml\output)
 -- Repeat step #15
 
