How to Setup a Hadoop File System (HDFS) on Windows 7
-----------------------------------------------------

Assumptions:
 A) You have Maven installed
 B) You have a Java JDK installed
 C) You have Cygwin installed (with openssh)
 D) You are running a 64-bit versions of Windows (Windows 7 or later)
 
 http://www.srccodes.com/p/article/38/build-install-configure-run-apache-hadoop-2.2.0-microsoft-windows-os
 
 
Finally Apache Hadoop 2.2.0 and later officially supports for running Hadoop on Microsoft Windows 
But, the "bin" distribution of Apache Hadoop 2.2.0 release does *NOT* contain some windows native components (like winutils.exe, hadoop.dll etc). As a result, if we try to run Hadoop in windows, we'll encounter ERROR util.Shell: Failed to locate the winutils binary in the hadoop binary path. 

In this article, we'll build the bin native distribution of hadoop from source, install, configure and run Hadoop in Windows Platform.
 
 
 
 
Procedures
----------
 1. Build the Hadoop binary distribution for Windows
   
    a. Download and install Microsoft .Net Framework 4.5
       1) Go to http://www.microsoft.com/en-us/download/details.aspx?id=30653
       2) Click Download
       3) Save dotNetFx45_Full_setup.exe to c:\vault
       4) Run c:\vault\dotNetFx45_Full_setup.exe
          a) In the first screen, click "I have read and accept the license terms"
             Press Install
          b) In the "Installation is complete" screen, Press Finish
          
 
    b. Download and install Microsoft Windows SDK v7.1
       1) Go to http://www.microsoft.com/en-in/download/details.aspx?id=8279
       2) Click the "Download" button
          -- You will be prompted to save winsdk_web.exe
          -- Save it to your c:\vault
       3) Run c:\vault\winsdk_web.exe
          a) In the "Windows SDK Setup Wizard" screen, press Next
          b) In the "End user license agreement" screen, Click "I agree" and press Next
          c) In the "Uninstall Options" screen, press Next
          d) In the "Install Locations" screen, go with the defaults and press Next
          e) In the "Installation Options" screen, go with the defaults and press Next
          f) In the "Begin Installation" screen, press Next
          
             NOTE:  This may take up to 15 minutes
          
          g) In the "Installation Complete" screen, 
             Uncheck "view the Windows SDK Release Notes"
             Press "Finish"
      
        
    c. Download and install the Visual C++ 2010 SP1 Compiler Update for Windows SDK v7.1
       1) Go to http://go.microsoft.com/fwlink/?LinkID=212355
          or
          Go to http://www.microsoft.com/en-us/download/details.aspx?id=4422
          NOTE:  This link provides more details:  http://blogs.msdn.com/b/vcblog/archive/2011/03/31/10148110.aspx
          
       2) Click "Download"
       3) In the screen titled, "Choose the download you want"
          select VC-Compiler-KB2519277.exe
          Press Next
       4) Save VC-Compiler-KB2519277.exe to your c:\vault
       5) Run c:\vault\VC-Compiler-KB2519277.exe
          a) In the "Software Update Visual C++ 2010 Compiler Update for Windows SDK"
             Press Next
          b) In the license agreement page, click "I have read and accept the license terms"
             Press Next
             
             The program will start downloading and intalling componenets
           
          c) In the final screen, it should display
             "The software update has been installed successfully"
             Press Finish
               

    d. Download and install Microsoft Visual Studio C++ 2010 Express (free)
       1) Go to http://download.microsoft.com/download/1/E/5/1E5F1C0A-0D5B-426A-A603-1798B951DDAE/VS2010Express1.iso
       2) Save to your c:\vault
       3) Right-click on c:\vault\VS2010Express1.iso -> 7zip -> Extract to VS2010Express1\
       4) Run c:\vault\VS2010Express1\setup.hta
          a) In the "Welcome to Visual Studio 2010 Express Setup" screen,
             Select Visual C++ 2010 Express
             1) In the Visual C++ 2010 Welcome screen, 
                Uncheck "Yes, send information about my setup experience.."
                Press Next
             2) In the License Terms screen, press "I have read and accept the license terms"
                Press Next
             3) In the Installation Options screen, 
                Uncheck Microsoft Silverlight
                Uncheck Microsoft Sql Server 2008 Express Service pack 1
                Press Next
             4) In the Destination Folder screen, press Install
             5) In the Setup Complete screen, press Exit

                NOTE:  If you are prompted to restart your computer, then restart now.
             
          b) Close the "Welcome to Visual Studio 2010 Express Setup" window
       
       
    e. Download and install Microsoft Visual Studio 2010 Service Pack 1
       1) Go to https://www.microsoft.com/en-us/download/details.aspx?id=23691
       2) Click "Download"
       3) Save VS10sp1-KB983509.exe to c:\vault
       4) Run c:\vault\VS10sp1-KB983509.exe
          a) In the first screen, Press Next
          b) In the next screen, Press "I have read and accept the license terms"
             Press Install
          c) In the Installation is complete screen, press Finish
          d) If you are prompted to restart your computer, then restart now.
       
          
    f. Add an environment variable called "Platform"
       NOTE:  The Microsoft SDK uses this to determine whether to compile 32-bit or 64-bit
              We are setting it to use the flag for 64-bit
              
       1) Open the Environment Variables in Windows by pressing <Start><Run>environment
       2) Under "User variables for..." [on the top of this popup], 
          click "New..."
             Variable name:  Platform
             Variable value: x64
    
          NOTES:  
              Variable name "Platform" is case sensitive.
              The Platform environment value must be either x64 or Win32
           
                 
    g. Download Protocol Buffers 2.5.0
       1) Go to http://protobuf.googlecode.com/files/protoc-2.5.0-win32.zip
       2) Save the file to c:\vault
       3) Right-click on c:\vault\protoc-2.5.0-win32.zip -> 7zip -> Extract Files....
          Extract To:  c:\tools\protobuf
          Press OK
          -- Now, you should have protocol buffers installed to c:\tools\protobuf
          
       4) Add c:\tools\protobuf to your PATH
          a) Open the Environment Variables in Windows by pressing <Start><Run>environment

          b) Under "User variables for..." [on the top of this popup], 
             Click "New..."  [if PATH already exists, then double-click on PATH and add a semicolon and append this to the end of the PATH]
                Variable name:  PATH
                Variable value: c:\tools\protobuf
       
              
              
    h. Make sure your JAVA_HOME environment variables does not have any spaces in it
       For example:  
           This is good:   C:\progra~1\Java\jdk1.7.0_75
           This is bad:    C:\Program Files\Java\jdk1.7.0_75 
      
      
    i. Make sure the cygwin/bin directory is in your PATH
     
    
    j. Download and install CMake
       1) Go to http://www.cmake.org/download/
       2) Under latest release, get the Windows Binary
          a) Click on cmake-3.3.0-win32-x86.exe
          b) Save it to c:\vault\cmake-3.3.0-win32-x86.exe
          
       3) Run c:\vault\cmake-3.3.0-win32-x86.exe
          a) On the Welcome screen, press Next
          b) On the License agreement creen, press "I agree"
          c) On the Install options, click "Add CMake to the system path for current user"
             press Next
          d) On the "Choose Install Location", 
             Set the destination folder to be c:\tools\CMake-3.3.0
             press Next
          e) On the "Choose Start Menu Folder", go with the defaults and press Install
          f) On the "Completing wizard setup", Press Finish
          
    
    k. Download and install the zlib compiled DLL and include files
       1) Go to http://www.zlib.net/
       2) Scroll down to  zlib compiled DLL, version....
          Click on http://zlib.net/zlib128-dll.zip
          Save the zfile to your c:\vault
          
       3) Right-click on c:\vault\zlib128-dll.zip -> 7zip -> Extract files...
          Extract To:  c:\tools\zlib-1.2.8\
          
       4) Add the directory that holds zlib1.dll to your PATH:  C:\tools\zlib-1.2.8
       
       5) Add the environment variable ZLIB_HOME to the directory that holds the zlib.h
          set ZLIB_HOME=C:\tools\zlib-1.2.8\include
          
          
    l. Download and install OpenSSL 1.0.1p with development files
       1) Go to http://www.openssl.org/related/binaries.html
       2) Select "Win64 OpenSSL v1.0.1p" (next to Works with MSVC++, Builder 3/4/5, and MinGW. Comes in form of self-install executables. )
          NOTE:  It should take you here:  http://slproweb.com/products/Win32OpenSSL.html
       3) Select Win64 OpenSSL v1.0.1p
          NOTE:  It should take you here:  http://slproweb.com/download/Win64OpenSSL-1_0_1p.exe         
       4) Save Win64OpenSSL-1_0_1p.exe to your c:\vault
       5) Run c:\vault\Win64OpenSSL-1_0_1p.exe
          a) In the "Welcome to the openSSL (64-bit) setup wizard" screen, press Next
          b) In the License Agreement screen, select "I accept" and press "Next"
          c) In the "Select destination location" screen
             Set the destination to c:\tools\openssl-1.0.1p
             Press Next
          d) In the "Select Start Menu Folder" screen, use the defaults and press Next
          e) In the "Select Additional Tasks", choose "The Openssl binaries /bin directory" and press Next
          f) In the "Ready to Install" screen, press Install
          
          
    m. Download hadoop 2.7.1 source to your c:\tools
       1) Open a browser and go to https://hadoop.apache.org/releases.html
       2) Click on the "source" link next to a version -- e.g., source for 2.7.1
          http://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.7.1/hadoop-2.7.1-src.tar.gz
           
       3) Click on one of the mirrors
          http://mirrors.sonic.net/apache/hadoop/common/hadoop-2.7.1/hadoop-2.7.1-src.tar.gz
           
       4) Save hadoop-2.7.1-src.tar.gz to your c:\vault
    
       5) Right-click on c:\vault\hadoop-2.7.1-src.tar.gz -> 7zip -> Extract Here....
          -- Now, you should have a c:\vault\hadoop-2.7.1-src.tar
      
       6) Right-click on c:\vault\hadoop-2.7.1-src.tar -> 7zip -> Extract To....
          Extract To:  c:\tools
          Press OK
          -- Now, you should have hadoop source located here:
              c:\tools\hadoop-2.7.1-src
           
            
    n. Compile Hadoop binaries for windows
       1) Open the Windows SDK Command Prompt as an Administrator 
          NOTE:  On some computers, you get permission denied errors if you do not do so
          
          Press <Start> sdk
          -- You should see Windows SDK 7.1 Command Prompt
          -- Right-click on Windows SDK 7.1 Command Prompt -> Run as Administrator
      
       2) DOS> cd /d c:\tools\hadoop-2.7.1-src
          DOS> mvn clean package -Pdist,native-win -DskipTests -Dtar
       
       3) Wait up to 25 minutes for it to finish compiling
       
          If everything goes well, hadoop binaries should be installed here:
             C:\tools\hadoop-2.7.1-src\hadoop-dist\target\hadoop-2.7.1.tar.gz
 
 
             

 2. Install Hadoop             
    a. Install the hadoop binaries to c:\tools\hadoop-2.7.1
       1) Browse to C:\tools\hadoop-2.7.1-src\hadoop-dist\target
       2) Right-click on hadoop-2.7.1.tar.gz -> 7-zip -> Extract Here
       3) Right-click on hadoop-2.7.1.tar    -> 7-zip -> Extract files...
          In the Extract to:  c:\tools
          Press OK
          
          Now, you should have hadoop files installed to here:
             C:\tools\hadoop-2.7.1
             
    b. Set environment  HADOOP_HOME = c:\tools\hadoop-2.7.1   
       1) Open the Environment Variables in Windows by pressing <Start><Run>environment

       2) Under "User variables for..." [on the top of this popup], 
             Click "New..."  [if PATH already exists, then double-click on PATH and add a semicolon and append this to the end of the PATH]
                Variable name:  HADOOP_HOME
                Variable value: c:\tools\hadoop-2.7.1
      
    c. Add %HADOOP_HOME%\bin to your PATH
       set PATH=....c:\tools\hadoop-2.7.1\bin
 
    d. Verify that hadoop is found
       1) Open a DOS window by pressing <Start><Run>CMD
       2) In the DOS window, type-in this:
          DOS> hadoop version

          You should see the following:
          Hadoop 2.7.1
          Subversion Unknown -r Unknown
          Compiled by Adam on 2015-07-26T03:20Z
          Compiled with protoc 2.5.0
          From source with checksum fc0a1a23fc1868e4d5ee7fa2b28a58a
          This command was run using /C:/tools/hadoop-2.7.1/share/hadoop/common/hadoop-common-2.7.1.jar
 
 
 
 3. Configure Hadoop
    a. Edit the C:\tools\hadoop-2.7.1\etc\hadoop\core-site.xml
        <?xml version="1.0" encoding="UTF-8"?>
        <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>        
        
            <configuration>
                <property>
                    <name>fs.defaultFS</name>
                    <value>hdfs://localhost:9000</value>
                </property>
            </configuration>
     
     
    b. Edit the C:\tools\hadoop-2.7.1\etc\hadoop\hdfs-site.xml   
       Note:  Create namenode and datanode directory under c:/hadoop/data/dfs/. 
       Note:  Set the datanode to listen on port 50001
          
        <?xml version="1.0" encoding="UTF-8"?>
        <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
        
            <configuration>
                <property>
                    <name>dfs.replication</name>
                    <value>1</value>
                </property>
                <property>
                    <name>dfs.namenode.name.dir</name>
                    <value>file:/hadoop/data/dfs/namenode</value>
                </property>
                <property>
                    <name>dfs.datanode.data.dir</name>
                    <value>file:/hadoop/data/dfs/datanode</value>
                </property>
                
                <property>
				    <name>dfs.datanode.address</name>
					<value>localhost:50001</value>
				</property>
            </configuration>
      
      
    c. Edit the C:\tools\hadoop-2.7.1\etc\hadoop\yarn-site.xml
      
        <?xml version="1.0"?>
        
         <configuration>
            <property>
               <name>yarn.nodemanager.aux-services</name>
               <value>mapreduce_shuffle</value>
            </property>
            <property>
               <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
               <value>org.apache.hadoop.mapred.ShuffleHandler</value>
            </property>
            <property>
               <name>yarn.application.classpath</name>
               <value>
                    %HADOOP_HOME%\etc\hadoop,
                    %HADOOP_HOME%\share\hadoop\common\*,
                    %HADOOP_HOME%\share\hadoop\common\lib\*,
                    %HADOOP_HOME%\share\hadoop\mapreduce\*,
                    %HADOOP_HOME%\share\hadoop\mapreduce\lib\*,
                    %HADOOP_HOME%\share\hadoop\hdfs\*,
                    %HADOOP_HOME%\share\hadoop\hdfs\lib\*,          
                    %HADOOP_HOME%\share\hadoop\yarn\*,
                    %HADOOP_HOME%\share\hadoop\yarn\lib\*
               </value>
            </property>
        </configuration> 
                 

    d. Edit the C:\tools\hadoop-2.7.1\etc\hadoop\mapred-site.xml
         1) Copy mapred-sit.xml.template to mapred-site.xml
         
         2) Copy this to the mapred-site.xml file
         
             <?xml version="1.0"?>
             <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
             
             <configuration>
                <property>
                   <name>mapreduce.framework.name</name>
                   <value>yarn</value>
                </property>
             </configuration>    
             
             
 4. Format the Name Node
    Open a DOS window in Administrator Mode
    DOS> cd %HADOOP_HOME%\bin
    DOS> hdfs namenode -format
       
        You should see this:
         
        STARTUP_MSG:   build = Unknown -r Unknown; compiled by 'adam' on 2015-07-26T16:37Z
        STARTUP_MSG:   java = 1.7.0_60
        ************************************************************/
        15/07/26 12:55:47 INFO namenode.NameNode: createNameNode [-format]
        Formatting using clusterid: CID-e29bd4ce-2e2e-415e-90a6-b2f627f61b0d
        15/07/26 12:55:48 INFO namenode.FSNamesystem: No KeyProvider found.
        15/07/26 12:55:48 INFO namenode.FSNamesystem: fsLock is fair:true
        15/07/26 12:55:48 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
        15/07/26 12:55:48 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
        15/07/26 12:55:48 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:0.000
        15/07/26 12:55:48 INFO blockmanagement.BlockManager: The block deletion will start around 2015 Jul 26 12:55:48
        15/07/26 12:55:48 INFO util.GSet: Computing capacity for map BlocksMap
        15/07/26 12:55:48 INFO util.GSet: VM type       = 64-bit
        15/07/26 12:55:48 INFO util.GSet: 2.0% max memory 889 MB = 17.8 MB
        15/07/26 12:55:48 INFO util.GSet: capacity      = 2^21 = 2097152 entries
        15/07/26 12:55:48 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false
        15/07/26 12:55:48 INFO blockmanagement.BlockManager: defaultReplication         = 1
        15/07/26 12:55:48 INFO blockmanagement.BlockManager: maxReplication             = 512
        15/07/26 12:55:48 INFO blockmanagement.BlockManager: minReplication             = 1
        15/07/26 12:55:48 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
        15/07/26 12:55:48 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
        15/07/26 12:55:48 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
        15/07/26 12:55:48 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
        15/07/26 12:55:48 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
        15/07/26 12:55:48 INFO namenode.FSNamesystem: fsOwner             = adam (auth:SIMPLE)
        15/07/26 12:55:48 INFO namenode.FSNamesystem: supergroup          = supergroup
        15/07/26 12:55:48 INFO namenode.FSNamesystem: isPermissionEnabled = true
        15/07/26 12:55:48 INFO namenode.FSNamesystem: HA Enabled: false
        15/07/26 12:55:48 INFO namenode.FSNamesystem: Append Enabled: true
        15/07/26 12:55:48 INFO util.GSet: Computing capacity for map INodeMap
        15/07/26 12:55:48 INFO util.GSet: VM type       = 64-bit
        15/07/26 12:55:48 INFO util.GSet: 1.0% max memory 889 MB = 8.9 MB
        15/07/26 12:55:48 INFO util.GSet: capacity      = 2^20 = 1048576 entries
        15/07/26 12:55:48 INFO namenode.FSDirectory: ACLs enabled? false
        15/07/26 12:55:48 INFO namenode.FSDirectory: XAttrs enabled? true
        15/07/26 12:55:48 INFO namenode.FSDirectory: Maximum size of an xattr: 16384
        15/07/26 12:55:48 INFO namenode.NameNode: Caching file names occuring more than 10 times
        15/07/26 12:55:48 INFO util.GSet: Computing capacity for map cachedBlocks
        15/07/26 12:55:48 INFO util.GSet: VM type       = 64-bit
        15/07/26 12:55:48 INFO util.GSet: 0.25% max memory 889 MB = 2.2 MB
        15/07/26 12:55:48 INFO util.GSet: capacity      = 2^18 = 262144 entries
        15/07/26 12:55:48 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
        15/07/26 12:55:48 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
        15/07/26 12:55:48 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
        15/07/26 12:55:48 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
        15/07/26 12:55:48 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
        15/07/26 12:55:48 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
        15/07/26 12:55:48 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
        15/07/26 12:55:48 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
        15/07/26 12:55:48 INFO util.GSet: Computing capacity for map NameNodeRetryCache
        15/07/26 12:55:48 INFO util.GSet: VM type       = 64-bit
        15/07/26 12:55:48 INFO util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
        15/07/26 12:55:48 INFO util.GSet: capacity      = 2^15 = 32768 entries
        15/07/26 12:55:48 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1500842503-192.168.1.2-1437929748421
        15/07/26 12:55:48 INFO common.Storage: Storage directory \hadoop\data\dfs\namenode has been successfully formatted.
        15/07/26 12:55:48 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
        15/07/26 12:55:48 INFO util.ExitUtil: Exiting with status 0
        15/07/26 12:55:48 INFO namenode.NameNode: SHUTDOWN_MSG:
        /************************************************************
        SHUTDOWN_MSG: Shutting down NameNode at anonymous-PC/192.168.1.2
        ************************************************************/
   
    A few notes about the formatting of the name node:
      A) "HA Enabled: false" 
          means that high availablity is not enabled     
      B) "Storage directory \hadoop\data\dfs\namenode has been successfully formatted." 
          means that A local directory is being formatted for the name node:
  
  
          
 5. Start HDFS (Start the Name Node and Data Node)
    DOS> cd %HADOOP_HOME%\sbin
    DOS> start-dfs 
        
         You should see 2 DOS windows open up
         1) Apache Hadoop Distribution - hadoop namenode
         2) Apache Hadoop Distribution - hadoop datanode
    
    
  
 6. Start MapReduce aka YARN (Resource Manager and Node Manager)
    DOS> cd %HADOOP_HOME%\sbin
    DOS> start-yarn
    
         You should see 2 DOS windows open up
         1) Apache Hadoop Distribution - yarn nodemanager
         2) Apache Hadoop Distribution - yarn resourcemanager
    
    
    
 7. Verify it is running
    a. Go to the NodeManager's url:
       http://localhost:8042/
        
    b. Go to the Namenode's website
       http://localhost:50070  
       
       
 8. Create a directory in your HDFS
    a. List what is in your HDFS top directory
       DOS> hadoop fs -ls /    # List what is in the root directory
            NOTE:  It should display nothing
         
    b. Create a directory called /tmp in HDFS
       DOS> hadoop fs -mkdir /tmp
       DOS> hadoop fs -chmod 1777 /tmp
       DOS> hadoop fs -ls /
            Found 1 items
            drwxrwxrwt   - adam supergroup          0 2015-07-26 18:52 /tmp
          
       
    c. Insert c:\temp\stuff.txt into your HDFS /tmp/stuff.txt
       1) Create a file called c:\temp\stuff.txt
          
       2) Use the hadoop command-line to insert it into your HDFS
          DOS> hadoop fs -put c:\temp\stuff.txt /tmp/stuff.txt   
 
          DOS> hadoop fs -ls /tmp
               Found 1 items
               -rw-r--r--   1 adam supergroup          6 2015-07-26 18:56 /tmp/stuff.txt
 
       3) Use the hadoop command-line to get an HDFS file and copy it to your local file system
          DOS> hadoop fs -get /tmp/stuff.txt c:\temp\stuff2.txt
        
        
       4) Display the content's of a file located in HDFS
          DOS> hadoop fs -cat /tmp/stuff.txt
               
            
 9. Run wordcount MapReduce job
    http://www.srccodes.com/p/article/45/run-hadoop-wordcount-mapreduce-example-windows
 
 
 
 10. Stop everything
    DOS> cd %HADOOP_HOME%\sbin
    DOS> stop-all
    


Setup Standalone Mode for debugging
-----------------------------------
In core-site.xml
    fs.default.name is file:///   (defailt)
    
In hdfs-site.xml
    dfs.replication is not set
    
In mapreduce-site.xml
    mapred.job.tracker is local   (default)
    